# import streamlit as st
# from zhipuai_module import sse_invoke_example  # å¯¼å…¥æ™ºè°±AIæ¨¡å—
# from content_processing import process_input  # å¯¼å…¥å†…å®¹å¤„ç†æ¨¡å—
# import time
# import re
# from collections import deque

# def memory_prompt(process_prompt_text, history):
#     """
#     ç»“åˆç”¨æˆ·çš„æœ€æ–°è¾“å…¥å’ŒèŠå¤©å†å²ï¼Œä½†åªåŒ…å«æœ€è¿‘çš„5æ¡å†å²è®°å½•ã€‚
#     """
#     if not isinstance(history, deque):
#         history = deque(history, maxlen=5)  # ç¡®ä¿å†å²è®°å½•ä¸ºdequeç±»å‹ï¼Œæœ€å¤§é•¿åº¦ä¸º5

#     # å°†å†å²è®°å½•è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
#     history_str = "\n".join([f"{message['role']}: {message['content']}" for message in history])
#     full_prompt = f"{history_str}\nUser: {process_prompt_text}"  # å°†ç”¨æˆ·æœ€æ–°è¾“å…¥æ·»åŠ åˆ°å†å²è®°å½•å­—ç¬¦ä¸²
#     return full_prompt

# def init_chat_interface():
#     """
#     åˆå§‹åŒ–èŠå¤©ç•Œé¢å¸ƒå±€ã€‚
#     """
#     with st.container():
#         col1_1, col1_2 = st.columns([1, 15])
#         with col1_1:
#             image_path = "images/im2.jpg"  # è®¾å®šå›¾ç‰‡è·¯å¾„
#             st.image(image_path, width=70)  # æ˜¾ç¤ºå›¾ç‰‡
#         with col1_2:
#             st.title("ChatEverything")  # æ˜¾ç¤ºæ ‡é¢˜
#     st.divider()  # æ·»åŠ åˆ†å‰²çº¿

#     with st.sidebar:

#         st.divider()  # æ·»åŠ åˆ†å‰²çº¿
#         # æ·»åŠ ä¾§è¾¹æ æŒ‰é’®ä»¥æ¸…ç†èŠå¤©è®°å½•
#         if st.sidebar.button('æ¸…ç†èŠå¤©è®°å½•'):
#             st.session_state.messages.clear()  # æ¸…ç†èŠå¤©è®°å½•
#         st.divider()
#         # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–ä»‹ç»æ€§æ–‡å­—æˆ–è¯´æ˜
#         st.write(
#             """
#         å°æç¤ºï¼š

#         1ã€è¾“å…¥ä»»æ„å†…å®¹å¼€å§‹æ¢ç´¢ï¼›

#         2ã€é“¾æ¥ç›´æ¥è¾“å…¥å¯¹è¯æ¡†å¯ä»¥è·å–å†…å®¹ï¼›

#         3ã€æ”¯æŒå¤šè½®å¯¹è¯ã€‚

#         """
#         )

# def handle_user_input():
#     """
#     è·å–å¹¶å¤„ç†ç”¨æˆ·è¾“å…¥ã€‚
#     """
#     if prompt_text := st.chat_input("è¯´ç‚¹ä»€ä¹ˆ?"):  # ç”¨æˆ·è¾“å…¥å­—æ®µ
#         user_avatar = "ğŸ¤”"  # ç”¨æˆ·å¤´åƒ
#         with st.chat_message("user", avatar=user_avatar):  # æ˜¾ç¤ºç”¨æˆ·ä¿¡æ¯
#             st.markdown(prompt_text)  # ä½¿ç”¨Markdownæ ¼å¼æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
#         return prompt_text
#     return None

# def process_and_display_response(prompt_text):
#     """
#     å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶å±•ç¤ºAIçš„å“åº”ã€‚
#     """
#     # å¤„ç†ç”¨æˆ·è¾“å…¥å†…å®¹
#     process_input(prompt_text, uploaded_file=None, template_file=None, process_function=None) #å› ä¸ºå…±ç”¨å†…å®¹å¤„ç†æ¨¡å—ï¼Œè¿™é‡Œåªä¼ é€’éƒ¨åˆ†çš„å˜é‡
#     process_prompt_text = st.session_state['combined_input']
#     ai_avatar = "ğŸ¤–"  # AIå¤´åƒ
    
#     with st.chat_message("ai", avatar=ai_avatar):
#         message_placeholder = st.empty()  # åˆ›å»ºä¸€ä¸ªç©ºæ¶ˆæ¯å ä½ç¬¦
#         full_response = ""
#         full_prompt = memory_prompt(process_prompt_text, st.session_state.messages)
#         with st.spinner('çƒ§è„‘ä¸­...'):  # æ˜¾ç¤ºåŠ è½½æç¤º
#             # é€šè¿‡æ™ºè°±AIæ¨¡å—è·å–å“åº”
#             assistant_response = sse_invoke_example(full_prompt)   

#             # æ¨¡æ‹Ÿæµå¼ä¼ è¾“æ‰“å­—æ•ˆæœ
#             for chunk in assistant_response.split():  
#                 full_response += chunk + " "
#                 time.sleep(0.088)  # çŸ­æš‚ç­‰å¾…ä»¥æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ
#                 message_placeholder.markdown(full_response + "â–Œ", unsafe_allow_html=True)

#         # åœ¨æœ€ç»ˆå±•ç¤ºæ¨¡å‹å›å¤å‰æ·»åŠ çŸ­æš‚å»¶è¿Ÿä½œä¸ºè¿‡æ¸¡
#         time.sleep(1)  # è¿™é‡Œçš„æ—¶é—´å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´    

#         # æ‰“å­—æ¨¡æ‹Ÿå®Œæ¯•åï¼Œæœ€åå‘ˆç°æ¨¡å‹è¿”å›çš„æ ¼å¼ï¼Œé¿å…æµå¼æ‰“å­—çš„æ¨¡ç‰ˆæ”¹å˜
#         message_placeholder.markdown(assistant_response, unsafe_allow_html=True)

#     return assistant_response

# def show_ChatEverything_page():
#     """
#     æ˜¾ç¤ºæ•´ä¸ªèŠå¤©é¡µé¢ã€‚
#     """
#     # åˆå§‹åŒ–èŠå¤©è®°å½•
#     if "messages" not in st.session_state:
#         st.session_state.messages = deque(maxlen=5)

#     # åˆå§‹åŒ–èŠå¤©ç•Œé¢
#     init_chat_interface()

#     # æ˜¾ç¤ºå†å²èŠå¤©è®°å½•
#     for message in st.session_state.messages:
#         with st.chat_message(message["role"], avatar=message["avatar"]):
#             st.markdown((message["content"]), unsafe_allow_html=True)

#     # å¤„ç†æ–°çš„ç”¨æˆ·è¾“å…¥
#     prompt_text = handle_user_input()
#     if prompt_text:
#         st.session_state.messages.append({"role": "user", "content": prompt_text, "avatar": "ğŸ¤”"})
#         full_response = process_and_display_response(prompt_text)
#         st.session_state.messages.append({"role": "ai", "content": full_response, "avatar": "ğŸ¤–"})

# if __name__ == "__main__":
#     show_ChatEverything_page()

import streamlit as st
import time
import re
from zhipuai_module import parse_function_call, glm_invoke
from collections import deque
from content_processing import process_input  # å¯¼å…¥å†…å®¹å¤„ç†æ¨¡å—

def memory_prompt(process_prompt_text, history):
    """
    ç»“åˆç”¨æˆ·çš„æœ€æ–°è¾“å…¥å’ŒèŠå¤©å†å²ï¼Œä½†åªåŒ…å«æœ€è¿‘çš„5æ¡å†å²è®°å½•ã€‚
    """
    if not isinstance(history, deque):
        history = deque(history, maxlen=5)  # ç¡®ä¿å†å²è®°å½•ä¸ºdequeç±»å‹ï¼Œæœ€å¤§é•¿åº¦ä¸º5

    # å°†å†å²è®°å½•è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
    history_str = "\n".join([f"{message['role']}: {message['content']}" for message in history])
    full_prompt = f"{history_str}\nUser: {process_prompt_text}"  # å°†ç”¨æˆ·æœ€æ–°è¾“å…¥æ·»åŠ åˆ°å†å²è®°å½•å­—ç¬¦ä¸²
    return full_prompt

def init_chat_interface():
    """
    åˆå§‹åŒ–èŠå¤©ç•Œé¢å¸ƒå±€ã€‚
    """
    with st.container():
        col1_1, col1_2 = st.columns([1, 15])
        with col1_1:
            image_path = "images/im2.jpg"  # è®¾å®šå›¾ç‰‡è·¯å¾„
            st.image(image_path, width=70)  # æ˜¾ç¤ºå›¾ç‰‡
        with col1_2:
            st.title("ChatEverything")  # æ˜¾ç¤ºæ ‡é¢˜
    st.divider()  # æ·»åŠ åˆ†å‰²çº¿

    with st.sidebar:

        st.divider()  # æ·»åŠ åˆ†å‰²çº¿
        # æ·»åŠ ä¾§è¾¹æ æŒ‰é’®ä»¥æ¸…ç†èŠå¤©è®°å½•
        if st.sidebar.button('æ¸…ç†èŠå¤©è®°å½•'):
            st.session_state.messages.clear()  # æ¸…ç†èŠå¤©è®°å½•
        st.divider()
        # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–ä»‹ç»æ€§æ–‡å­—æˆ–è¯´æ˜
        st.write(
            """
        å°æç¤ºï¼š

        1ã€è¾“å…¥ä»»æ„å†…å®¹å¼€å§‹æ¢ç´¢ï¼›

        2ã€é“¾æ¥ç›´æ¥è¾“å…¥å¯¹è¯æ¡†å¯ä»¥è·å–å†…å®¹ï¼›

        3ã€æ”¯æŒå¤šè½®å¯¹è¯ã€‚

        """
        )

def memory_prompt(prompt_text, history):
    """
    ç»“åˆç”¨æˆ·çš„æœ€æ–°è¾“å…¥å’ŒèŠå¤©å†å²ï¼Œä½†åªåŒ…å«æœ€è¿‘çš„5æ¡å†å²è®°å½•ã€‚
    """
    if not isinstance(history, deque):
        history = deque(history, maxlen=5)

    history_str = "\n".join([f"{message['role']}: {message['content']}" for message in history])
    full_prompt = f"{history_str}\nUser: {prompt_text}"
    return full_prompt

def handle_user_input():
    """
    è·å–å¹¶æ˜¾ç¤ºç”¨æˆ·è¾“å…¥ã€‚
    """
    prompt_text = st.chat_input("è¯´ç‚¹ä»€ä¹ˆ?")
    if prompt_text:
        user_avatar = "ğŸ¤”"
        with st.chat_message("user", avatar=user_avatar):
            st.markdown(prompt_text)
        return prompt_text
    return None

def model_response(prompt_text):
    """
    æ ¹æ®ç”¨æˆ·è¾“å…¥è·å–æ¨¡å‹çš„å“åº”ã€‚
    """

    # å¤„ç†ç”¨æˆ·è¾“å…¥å†…å®¹
    process_input(prompt_text, uploaded_file=None, template_file=None, process_function=None) #å› ä¸ºå…±ç”¨å†…å®¹å¤„ç†æ¨¡å—ï¼Œè¿™é‡Œåªä¼ é€’éƒ¨åˆ†çš„å˜é‡
    process_prompt_text = st.session_state['combined_input']

    user_input = memory_prompt(process_prompt_text, st.session_state.messages)
    if user_input:
        messages = [
            {"role": "system", "content": "ä¸è¦å‡è®¾æˆ–çŒœæµ‹ä¼ å…¥å‡½æ•°çš„å‚æ•°å€¼ã€‚å¦‚æœç”¨æˆ·çš„æè¿°ä¸æ˜ç¡®ï¼Œè¯·è¦æ±‚ç”¨æˆ·æä¾›å¿…è¦ä¿¡æ¯"},
            {"role": "user", "content": user_input}
        ]
        response = glm_invoke(messages)
        messages.append(response.choices[0].message.model_dump())
        
        ai_response = parse_function_call(response, messages)

        return ai_response

def show_ChatEverything_page():
    """
    æ˜¾ç¤ºæ•´ä¸ªèŠå¤©é¡µé¢ã€‚
    """
    if "messages" not in st.session_state:
        st.session_state.messages = deque(maxlen=5)

    init_chat_interface()

    # æ˜¾ç¤ºå†å²èŠå¤©è®°å½•ï¼Œè®©å†å²æ¶ˆæ¯ä¿æŒæ˜¾ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"], avatar=message["avatar"]):
            st.markdown(message["content"], unsafe_allow_html=True)

    # å¤„ç†æ–°çš„ç”¨æˆ·è¾“å…¥
    prompt_text = handle_user_input()
    if prompt_text:
        st.session_state.messages.append({"role": "user", "content": prompt_text, "avatar": "ğŸ¤”"})
        
        ai_response = model_response(prompt_text)
        if ai_response:
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.markdown(ai_response)
            st.session_state.messages.append({"role": "assistant", "content": ai_response, "avatar": "ğŸ¤–"})

if __name__ == "__main__":
    show_ChatEverything_page()