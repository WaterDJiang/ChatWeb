import streamlit as st
import time
import re
from zhipuai_module import parse_function_call, glm_invoke
from collections import deque
from content_processing import process_input  # å¯¼å…¥å†…å®¹å¤„ç†æ¨¡å—

def memory_prompt(process_prompt_text, history):
    """
    ç»“åˆç”¨æˆ·çš„æœ€æ–°è¾“å…¥å’ŒèŠå¤©å†å²ï¼Œä½†åªåŒ…å«æœ€è¿‘çš„5æ¡å†å²è®°å½•ã€‚
    """
    if not isinstance(history, deque):
        history = deque(history, maxlen=5)  # ç¡®ä¿å†å²è®°å½•ä¸ºdequeç±»å‹ï¼Œæœ€å¤§é•¿åº¦ä¸º5

    # å°†å†å²è®°å½•è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
    history_str = "\n".join([f"{message['role']}: {message['content']}" for message in history])
    full_prompt = f"{history_str}\nUser: {process_prompt_text}"  # å°†ç”¨æˆ·æœ€æ–°è¾“å…¥æ·»åŠ åˆ°å†å²è®°å½•å­—ç¬¦ä¸²
    return full_prompt

def init_chat_interface():
    """
    åˆå§‹åŒ–èŠå¤©ç•Œé¢å¸ƒå±€ã€‚
    """
    with st.container():
        col1_1, col1_2 = st.columns([1, 15])
        with col1_1:
            image_path = "images/im2.jpg"  # è®¾å®šå›¾ç‰‡è·¯å¾„
            st.image(image_path, width=70)  # æ˜¾ç¤ºå›¾ç‰‡
        with col1_2:
            st.title("ChatEverything")  # æ˜¾ç¤ºæ ‡é¢˜
    st.divider()  # æ·»åŠ åˆ†å‰²çº¿

    with st.sidebar:

        st.divider()  # æ·»åŠ åˆ†å‰²çº¿
        # æ·»åŠ ä¾§è¾¹æ æŒ‰é’®ä»¥æ¸…ç†èŠå¤©è®°å½•
        if st.sidebar.button('æ¸…ç†èŠå¤©è®°å½•'):
            st.session_state.messages.clear()  # æ¸…ç†èŠå¤©è®°å½•
        st.divider()
        # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–ä»‹ç»æ€§æ–‡å­—æˆ–è¯´æ˜
        st.write(
            """
        å°æç¤ºï¼š

        1ã€è¾“å…¥ä»»æ„å†…å®¹å¼€å§‹æ¢ç´¢ï¼›

        2ã€é“¾æ¥ç›´æ¥è¾“å…¥å¯¹è¯æ¡†å¯ä»¥è·å–å†…å®¹ï¼›

        3ã€æ”¯æŒå¤šè½®å¯¹è¯ã€‚

        """
        )

def memory_prompt(prompt_text, history):
    """
    ç»“åˆç”¨æˆ·çš„æœ€æ–°è¾“å…¥å’ŒèŠå¤©å†å²ï¼Œä½†åªåŒ…å«æœ€è¿‘çš„5æ¡å†å²è®°å½•ã€‚
    """
    if not isinstance(history, deque):
        history = deque(history, maxlen=5)

    history_str = "\n".join([f"{message['role']}: {message['content']}" for message in history])
    full_prompt = f"{history_str}\nUser: {prompt_text}"
    return full_prompt

def handle_user_input():
    """
    è·å–å¹¶æ˜¾ç¤ºç”¨æˆ·è¾“å…¥ã€‚
    """
    prompt_text = st.chat_input("è¯´ç‚¹ä»€ä¹ˆ?")
    if prompt_text:
        user_avatar = "ğŸ¤”"
        with st.chat_message("user", avatar=user_avatar):
            st.markdown(prompt_text)
        return prompt_text
    return None

def model_response(prompt_text):
    """
    æ ¹æ®ç”¨æˆ·è¾“å…¥è·å–æ¨¡å‹çš„å“åº”ã€‚
    """

    # å¤„ç†ç”¨æˆ·è¾“å…¥å†…å®¹
    process_input(prompt_text, uploaded_file=None, template_file=None, process_function=None) #å› ä¸ºå…±ç”¨å†…å®¹å¤„ç†æ¨¡å—ï¼Œè¿™é‡Œåªä¼ é€’éƒ¨åˆ†çš„å˜é‡
    process_prompt_text = st.session_state['combined_input']

    user_input = memory_prompt(process_prompt_text, st.session_state.messages)
    if user_input:
        messages = [
            {"role": "system", "content": "ä¸è¦å‡è®¾æˆ–çŒœæµ‹ä¼ å…¥å‡½æ•°çš„å‚æ•°å€¼ã€‚å¦‚æœç”¨æˆ·çš„æè¿°ä¸æ˜ç¡®ï¼Œè¯·è¦æ±‚ç”¨æˆ·æä¾›å¿…è¦ä¿¡æ¯"},
            {"role": "user", "content": user_input}
        ]
        response = glm_invoke(messages)
        messages.append(response.choices[0].message.model_dump())
        
        ai_response = parse_function_call(response, messages)

        return ai_response

def show_ChatEverything_page():
    """
    æ˜¾ç¤ºæ•´ä¸ªèŠå¤©é¡µé¢ã€‚
    """
    if "messages" not in st.session_state:
        st.session_state.messages = deque(maxlen=5)

    init_chat_interface()

    # æ˜¾ç¤ºå†å²èŠå¤©è®°å½•ï¼Œè®©å†å²æ¶ˆæ¯ä¿æŒæ˜¾ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"], avatar=message["avatar"]):
            st.markdown(message["content"], unsafe_allow_html=True)

    # å¤„ç†æ–°çš„ç”¨æˆ·è¾“å…¥
    prompt_text = handle_user_input()
    if prompt_text:
        st.session_state.messages.append({"role": "user", "content": prompt_text, "avatar": "ğŸ¤”"})
        
        ai_response = model_response(prompt_text)
        if ai_response:
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.markdown(ai_response, unsafe_allow_html=True)
            st.session_state.messages.append({"role": "assistant", "content": ai_response, "avatar": "ğŸ¤–"})

if __name__ == "__main__":
    show_ChatEverything_page()
