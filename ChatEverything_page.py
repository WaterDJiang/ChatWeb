
import streamlit as st
from zhipuai_module import sse_invoke_example
from content_processing import process_input
import time
import re
from collections import deque

def memory_prompt(process_prompt_text, history):
    """
    ä»…åŒ…å«æœ€è¿‘çš„5æ¡å†å²è®°å½•ã€‚
    """
    if not isinstance(history, deque):
        history = deque(history, maxlen=5)

    history_str = "\n".join([f"{message['role']}: {message['content']}" for message in history])
    full_prompt = f"{history_str}\nUser: {process_prompt_text}"
    return full_prompt

def init_chat_interface():
    """
    åˆå§‹åŒ–èŠå¤©ç•Œé¢ã€‚
    """
    with st.container():
        col1_1, col1_2 = st.columns([1, 15])
        with col1_1:
            image_path = "images/im2.jpg"  # æ›´æ”¹ä¸ºæ‚¨çš„å›¾ç‰‡è·¯å¾„
            st.image(image_path, width=70)
        with col1_2:
            st.title("ChatEverything")
    st.divider()

    if st.sidebar.button('æ¸…ç†èŠå¤©è®°å½•'):
        st.session_state.messages.clear()

def handle_user_input():
    """
    å¤„ç†ç”¨æˆ·è¾“å…¥ã€‚
    """
    if prompt_text := st.chat_input("è¯´ç‚¹ä»€ä¹ˆ?"):
        user_avatar = "ğŸ¤”"
        with st.chat_message("user", avatar=user_avatar):
            st.markdown(prompt_text)
        return prompt_text
    return None

def process_and_display_response(prompt_text):
    """
    å¤„ç†å¹¶å±•ç¤ºå“åº”ã€‚
    """
    # é€šè¿‡content_processing æ¨¡å—å¤„ç†å†…å®¹
    process_input(prompt_text, uploaded_file = None, template_file = None , process_function = None) 
    process_prompt_text = st.session_state['combined_input']
    ai_avatar = "ğŸ¤–"
    with st.chat_message("ai", avatar=ai_avatar):
        message_placeholder = st.empty()
        full_response = ""
        full_prompt = memory_prompt(process_prompt_text, st.session_state.messages)
        with st.spinner('å¤„ç†ä¸­...'):
            # å†å²æ–‡æœ¬æ•´åˆåé€šè¿‡æ¨¡å‹è·å–å›å¤
            assistant_response = sse_invoke_example(full_prompt)   

            #æ¨¡æ‹Ÿæµå¼ä¼ è¾“æ‰“å­—æ•ˆæœ
            for chunk in assistant_response.split():  
                full_response += chunk + " "
                time.sleep(0.088)
                message_placeholder.markdown(full_response + "â–Œ", unsafe_allow_html=True)

        # åœ¨æœ€ç»ˆå±•ç¤ºæ¨¡å‹å›å¤å‰æ·»åŠ çŸ­æš‚å»¶è¿Ÿä½œä¸ºè¿‡æ¸¡
        time.sleep(1)  # è¿™é‡Œçš„æ—¶é—´å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´    

        #æ‰“å­—æ¨¡æ‹Ÿå®Œæ¯•åï¼Œæœ€åå‘ˆç°æ¨¡å‹è¿”å›çš„æ ¼å¼ï¼Œé¿å…æµå¼æ‰“å­—çš„æ¨¡ç‰ˆæ”¹å˜   
        message_placeholder.markdown(assistant_response, unsafe_allow_html=True)

    return assistant_response

def show_ChatEverything_page():
    """
    æ˜¾ç¤ºä¸»é¡µé¢ã€‚
    """
    if "messages" not in st.session_state:
        st.session_state.messages = deque(maxlen=5)

    init_chat_interface()

    for message in st.session_state.messages:
        with st.chat_message(message["role"], avatar=message["avatar"]):
            st.markdown((message["content"]), unsafe_allow_html=True)

    prompt_text = handle_user_input()
    if prompt_text:
        st.session_state.messages.append({"role": "user", "content": prompt_text, "avatar": "ğŸ¤”"})
        full_response = process_and_display_response(prompt_text)
        st.session_state.messages.append({"role": "ai", "content": full_response, "avatar": "ğŸ¤–"})

if __name__ == "__main__":
    show_ChatEverything_page()
